{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2a8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f54762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\forgery detection model\\\\image_forgery_detection_model\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720bb8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687ffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\forgery detection model\\\\image_forgery_detection_model'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a995c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreprocessingConfig:\n",
    "    root_dir: Path\n",
    "    data_source: Path\n",
    "    resaved_path: Path\n",
    "    pickle_save: Path\n",
    "    params: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "538cd30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d747ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH):\n",
    "    \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_preprocessing_config(self) -> DataPreprocessingConfig:\n",
    "        \n",
    "        config = self.config.data_preprocessing\n",
    "        params = self.params.preprocessing\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_preprocessing_config = DataPreprocessingConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            data_source=Path(config.data_source),\n",
    "            resaved_path=Path(config.resaved_path),\n",
    "            pickle_save=Path(config.pickle_save),\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        return data_preprocessing_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83688961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageChops, ImageEnhance, UnidentifiedImageError\n",
    "import os\n",
    "import joblib\n",
    "from cnnClassifier import logger\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4cd8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    def __init__(self, config: DataPreprocessingConfig):\n",
    "        \"\"\"\n",
    "        Initializes the DataPreprocessing class with configuration\n",
    "        \"\"\"\n",
    "        logger.info(\"Initializing DataPreprocessing\")\n",
    "        self.config = config\n",
    "        self.params = config.params\n",
    "        self.data_label = ['Au', 'Tp']\n",
    "        self.df = self._create_dataframe()\n",
    "\n",
    "    def _create_dataframe(self):\n",
    "        \"\"\"\n",
    "        Creates a DataFrame with image paths and labels from the data source\n",
    "        \"\"\"\n",
    "        logger.info(f\"Creating DataFrame from data source: {self.config.data_source}\")\n",
    "        label_lst = []\n",
    "        img_lst = []\n",
    "        for label in self.data_label:\n",
    "            label_path = os.path.join(self.config.data_source, label)\n",
    "            if not os.path.exists(label_path):\n",
    "                logger.error(f\"Directory not found: {label_path}\")\n",
    "                continue\n",
    "            for img_file in os.listdir(label_path):\n",
    "                img_lst.append(os.path.join(label_path, img_file))\n",
    "                label_lst.append(label)\n",
    "        df = pd.DataFrame({'img': img_lst, 'label': label_lst})\n",
    "        logger.info(f\"DataFrame created with {len(df)} entries\")\n",
    "        return df\n",
    "\n",
    "    def resave(self):\n",
    "        \"\"\"\n",
    "        Resaves images as JPEGs with specified quality and updates DataFrame\n",
    "        \"\"\"\n",
    "        logger.info(f\"Starting resave process with quality: {self.params.quality}\")\n",
    "        resaved_path = self.config.resaved_path\n",
    "        os.makedirs(resaved_path, exist_ok=True)\n",
    "        skipped_files = {'non_image': 0, 'error': 0}\n",
    "        for index, row in self.df.iterrows():\n",
    "            img_file = row['img']\n",
    "            if img_file.lower().endswith(tuple(self.params.valid_extensions)):\n",
    "                try:\n",
    "                    img = Image.open(img_file).convert('RGB')\n",
    "                    img_file_name = os.path.basename(img_file)\n",
    "                    resaved_name = os.path.splitext(img_file_name)[0] + '_resaved.jpg'\n",
    "                    save_path = os.path.join(self.config.resaved_path, resaved_name)\n",
    "                    img.save(save_path, 'JPEG', quality=self.params.quality, optimize=True)\n",
    "                    img.close()  # Close image to prevent WinError 5\n",
    "                    logger.debug(f\"Resaved image: {save_path}\")\n",
    "                except UnidentifiedImageError as e:\n",
    "                    logger.error(f\"Cannot identify image file {img_file}: {e}\")\n",
    "                    skipped_files['error'] += 1\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error resaving {img_file}: {e}\")\n",
    "                    skipped_files['error'] += 1\n",
    "            else:\n",
    "                skipped_files['non_image'] += 1\n",
    "        self.df['img_resaved'] = self.df['img'].apply(\n",
    "            lambda x: os.path.join(self.config.resaved_path, os.path.splitext(os.path.basename(x))[0] + '_resaved.jpg')\n",
    "        )\n",
    "        logger.info(\"Resaved image paths added to DataFrame\")\n",
    "        if skipped_files['non_image'] > 0:\n",
    "            print(f\"Skipped {skipped_files['non_image']} files in resave due to non-image file extensions\")\n",
    "        if skipped_files['error'] > 0:\n",
    "            print(f\"Skipped {skipped_files['error']} files in resave due to errors (e.g., unidentified image)\")\n",
    "\n",
    "    def img_difference(self, org, resaved):\n",
    "        \"\"\"\n",
    "        Computes the enhanced difference between original and resaved images\n",
    "        \"\"\"\n",
    "        logger.debug(f\"Computing difference between {org} and {resaved}\")\n",
    "        try:\n",
    "            org_img = Image.open(org).convert('RGB')\n",
    "            resaved_img = Image.open(resaved).convert('RGB')\n",
    "            diff = ImageChops.difference(org_img, resaved_img)\n",
    "            extrema = diff.getextrema()\n",
    "            max_diff = max([ex[1] for ex in extrema])\n",
    "            if max_diff == 0:\n",
    "                max_diff = 1\n",
    "            scale = self.params.normalization_scale / max_diff\n",
    "            diff = ImageEnhance.Brightness(diff).enhance(scale)\n",
    "            enhancer = ImageEnhance.Sharpness(diff)\n",
    "            diff = enhancer.enhance(self.params.sharpness_factor)\n",
    "            org_img.close()  # Close image to prevent WinError 5\n",
    "            resaved_img.close()  # Close image to prevent WinError 5\n",
    "            logger.debug(f\"Difference computed for {org}\")\n",
    "            return diff\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {org} and {resaved}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def prep_dataset(self):\n",
    "        \"\"\"\n",
    "        Prepares dataset by computing image differences and creating feature arrays\n",
    "        \"\"\"\n",
    "        logger.info(\"Preparing dataset\")\n",
    "        valid_extensions = tuple(self.params.valid_extensions)\n",
    "        skipped_files = {'invalid_extension': 0, 'failed_diff': 0, 'error': 0}\n",
    "        # Pre-allocate arrays\n",
    "        n_samples = len(self.df)\n",
    "        feature_size = self.params.image_size[0] * self.params.image_size[1] * 3\n",
    "        X = np.empty((n_samples, feature_size), dtype=np.float32)\n",
    "        y = np.empty((n_samples, 2), dtype=np.float32)\n",
    "        idx = 0\n",
    "        for index, row in self.df.iterrows():\n",
    "            if (row['img'].lower().endswith(valid_extensions) and \n",
    "                row['img_resaved'].lower().endswith(valid_extensions)):\n",
    "                try:\n",
    "                    diff = self.img_difference(row['img'], row['img_resaved'])\n",
    "                    if diff is not None:\n",
    "                        x = diff.resize(tuple(self.params.image_size))\n",
    "                        X[idx] = np.array(x, dtype=np.float32).flatten() / self.params.normalization_scale\n",
    "                        y[idx] = [1, 0] if row['label'] == 'Au' else [0, 1]\n",
    "                        logger.debug(f\"Processed image: {row['img']}\")\n",
    "                        idx += 1\n",
    "                    else:\n",
    "                        skipped_files['failed_diff'] += 1\n",
    "                except (UnidentifiedImageError, FileNotFoundError) as e:\n",
    "                    logger.error(f\"Skipping file {row['img']} due to error: {e}\")\n",
    "                    skipped_files['error'] += 1\n",
    "            else:\n",
    "                skipped_files['invalid_extension'] += 1\n",
    "        # Trim arrays to actual size\n",
    "        X = X[:idx]\n",
    "        y = y[:idx]\n",
    "        logger.info(f\"Dataset prepared with {len(X)} samples\")\n",
    "        if skipped_files['invalid_extension'] > 0:\n",
    "            print(f\"Skipped {skipped_files['invalid_extension']} files in prep_dataset due to invalid file extensions\")\n",
    "        if skipped_files['failed_diff'] > 0:\n",
    "            print(f\"Skipped {skipped_files['failed_diff']} files in prep_dataset due to failed difference computation\")\n",
    "        if skipped_files['error'] > 0:\n",
    "            print(f\"Skipped {skipped_files['error']} files in prep_dataset due to errors (e.g., unidentified image or file not found)\")\n",
    "        return X, y\n",
    "\n",
    "    def delete_resaved(self):\n",
    "        \"\"\"\n",
    "        Deletes the resaved directory and its contents\n",
    "        \"\"\"\n",
    "        logger.info(f\"Deleting resaved directory: {self.config.resaved_path}\")\n",
    "        try:\n",
    "            shutil.rmtree(self.config.resaved_path)\n",
    "            logger.info(f\"Successfully deleted resaved directory: {self.config.resaved_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error deleting resaved directory {self.config.resaved_path}: {e}\")\n",
    "\n",
    "    def save_dataset(self):\n",
    "        \"\"\"\n",
    "        Saves the processed dataset as joblib files and deletes resaved directory\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting dataset saving process\")\n",
    "        self.resave()\n",
    "        pickle_save = self.config.pickle_save\n",
    "        os.makedirs(pickle_save, exist_ok=True)\n",
    "        X, y = self.prep_dataset()\n",
    "        x_path = os.path.join(self.config.pickle_save, 'X_90.joblib')\n",
    "        y_path = os.path.join(self.config.pickle_save, 'y.joblib')\n",
    "        joblib.dump(X, x_path)\n",
    "        joblib.dump(y, y_path)\n",
    "        logger.info(f\"Dataset saved to {x_path} and {y_path}\")\n",
    "        self.delete_resaved()\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e08d812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-08 19:22:42,288: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-08-08 19:22:42,306: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-08-08 19:22:42,309: INFO: common: created directory at: artifacts]\n",
      "[2025-08-08 19:22:42,311: INFO: common: created directory at: artifacts/data_preprocessing]\n",
      "[2025-08-08 19:22:42,312: INFO: 2383036555: Initializing DataPreprocessing]\n",
      "[2025-08-08 19:22:42,314: INFO: 2383036555: Creating DataFrame from data source: artifacts\\data_ingestion\\CASIA2]\n",
      "[2025-08-08 19:22:42,365: INFO: 2383036555: DataFrame created with 9555 entries]\n",
      "[2025-08-08 19:22:42,367: INFO: 2383036555: Starting dataset saving process]\n",
      "[2025-08-08 19:22:42,369: INFO: 2383036555: Starting resave process with quality: 90]\n",
      "[2025-08-08 19:25:29,709: INFO: 2383036555: Resaved image paths added to DataFrame]\n",
      "Skipped 54 files in resave due to non-image file extensions\n",
      "[2025-08-08 19:25:29,712: INFO: 2383036555: Preparing dataset]\n",
      "[2025-08-08 19:30:50,473: INFO: 2383036555: Dataset prepared with 9501 samples]\n",
      "Skipped 54 files in prep_dataset due to invalid file extensions\n",
      "[2025-08-08 19:30:52,931: INFO: 2383036555: Dataset saved to artifacts\\data_preprocessing\\pickle\\X_90.joblib and artifacts\\data_preprocessing\\pickle\\y.joblib]\n",
      "[2025-08-08 19:30:52,932: INFO: 2383036555: Deleting resaved directory: artifacts\\data_preprocessing\\resaved]\n",
      "[2025-08-08 19:30:55,955: INFO: 2383036555: Successfully deleted resaved directory: artifacts\\data_preprocessing\\resaved]\n",
      "[2025-08-08 19:30:55,958: INFO: 3107596882: Data preprocessing pipeline completed]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_preprocessing_config = config.get_data_preprocessing_config()\n",
    "    preprocessor = DataPreprocessing(config=data_preprocessing_config)\n",
    "    X, y = preprocessor.save_dataset()\n",
    "    logger.info(\"Data preprocessing pipeline completed\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Pipeline failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30090e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".imagemodel (3.10.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
