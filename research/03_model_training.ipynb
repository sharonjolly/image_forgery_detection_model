{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7365512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b381fadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\forgery detection model\\\\image_forgery_detection_model\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a30173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599e8e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\forgery detection model\\\\image_forgery_detection_model'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e43feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    load_data: Path\n",
    "    save_model: Path\n",
    "    params: dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4719d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    load_data: Path\n",
    "    save_model: Path\n",
    "    params: dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74527b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6affc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH):\n",
    "    \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        \n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.trainer\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            load_data=Path(config.load_data),\n",
    "            save_model=Path(config.save_model),\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d9021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from keras.optimizers import Adam\n",
    "from cnnClassifier import logger\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be98e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer(Sequence):\n",
    "    def __init__(self, config: ModelTrainerConfig, **kwargs):\n",
    "        \"\"\"\n",
    "        Constructor: Sets up ModelTrainer with given configuration settings.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        logger.info(\"ModelTrainer instance created\")\n",
    "        self.config = config\n",
    "        self.params = config.params\n",
    "        self.model = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.train_indexes = None\n",
    "        self.val_indexes = None\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Calculates total training batches per epoch.\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.X_train) / self.params['batch_size']))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Fetches a batch of training data.\n",
    "        \"\"\"\n",
    "        indexes = self.train_indexes[index * self.params['batch_size']:(index + 1) * self.params['batch_size']]\n",
    "        X = [self.X_train[k] for k in indexes]\n",
    "        y = [self.y_train[k] for k in indexes]\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Reshuffles the training set indices after each epoch.\n",
    "        \"\"\"\n",
    "        self.train_indexes = np.arange(len(self.X_train))\n",
    "        np.random.shuffle(self.train_indexes)\n",
    "\n",
    "    def get_validation_data(self):\n",
    "        \"\"\"\n",
    "        Returns a generator that yields validation data in batches.\n",
    "        \"\"\"\n",
    "        class ValidationGenerator(Sequence):\n",
    "            def __init__(self, X, y, batch_size, **kwargs):\n",
    "                super().__init__(**kwargs)\n",
    "                self.X = X\n",
    "                self.y = y\n",
    "                self.batch_size = batch_size\n",
    "                self.indexes = np.arange(len(self.X))\n",
    "\n",
    "            def __len__(self):\n",
    "                return int(np.floor(len(self.X) / self.batch_size))\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "                X = [self.X[k] for k in indexes]\n",
    "                y = [self.y[k] for k in indexes]\n",
    "                return np.array(X), np.array(y)\n",
    "\n",
    "        return ValidationGenerator(self.X_test, self.y_test, self.params['batch_size'])\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads dataset arrays from serialized joblib files.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Attempting to load dataset from {self.config.load_data}\")\n",
    "        try:\n",
    "            x_path = self.config.load_data / 'X_90.joblib'\n",
    "            y_path = self.config.load_data / 'y.joblib'\n",
    "            X = joblib.load(x_path)\n",
    "            y = joblib.load(y_path)\n",
    "            logger.info(f\"Dataset loaded successfully: X={X.shape}, y={y.shape}\")\n",
    "            return X, y\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load dataset: {e}\")\n",
    "            raise\n",
    "\n",
    "    def split_data(self, X, y):\n",
    "        \"\"\"\n",
    "        Divides the dataset into training and testing subsets.\n",
    "        \"\"\"\n",
    "        logger.info(\"Partitioning dataset into training and testing sets\")\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            logger.info(f\"Train: X={X_train.shape}, y={y_train.shape} | Test: X={X_test.shape}, y={y_test.shape}\")\n",
    "            return X_train, X_test, y_train, y_test\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data split failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def preprocess_data(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"\n",
    "        Prepares data shapes for CNN model and sets training indices.\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting preprocessing of dataset\")\n",
    "        try:\n",
    "            X_train = X_train.reshape(X_train.shape[0], 128, 128, 3)\n",
    "            X_test = X_test.reshape(X_test.shape[0], 128, 128, 3)\n",
    "            y_train = y_train.reshape(y_train.shape[0], 2)\n",
    "            y_test = y_test.reshape(y_test.shape[0], 2)\n",
    "            logger.info(f\"Reshaped: X_train={X_train.shape}, X_test={X_test.shape}\")\n",
    "            logger.info(f\"Reshaped: y_train={y_train.shape}, y_test={y_test.shape}\")\n",
    "\n",
    "            self.X_train, self.X_test = X_train, X_test\n",
    "            self.y_train, self.y_test = y_train, y_test\n",
    "            self.train_indexes = np.arange(len(self.X_train))\n",
    "            np.random.shuffle(self.train_indexes)\n",
    "            logger.info(\"Data preprocessing finished\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Preprocessing error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Constructs the CNN architecture for training.\n",
    "        \"\"\"\n",
    "        logger.info(\"Constructing CNN model architecture\")\n",
    "        try:\n",
    "            model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "                tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(2, activation='softmax')\n",
    "            ])\n",
    "            logger.info(\"CNN model successfully built\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Model creation failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Executes the model training process and saves the best weights.\n",
    "        \"\"\"\n",
    "        logger.info(\"Initiating training sequence\")\n",
    "        try:\n",
    "            self.model = self.build_model()\n",
    "            optimizer = self.params['optimizer']\n",
    "            metrics = [metric.lower() if metric == 'accuracy' else getattr(tf.keras.metrics, metric)() \n",
    "                       for metric in self.params['metrics']]\n",
    "            self.model.compile(optimizer=optimizer, \n",
    "                              loss='categorical_crossentropy', \n",
    "                              metrics=metrics)\n",
    "            self.model.summary()\n",
    "\n",
    "            cal1 = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss', \n",
    "                patience=self.params['patience'], \n",
    "                restore_best_weights=True\n",
    "            )\n",
    "            cal2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "                str(self.config.save_model / 'model.keras'), \n",
    "                monitor='val_loss', \n",
    "                save_best_only=True\n",
    "            )\n",
    "            \n",
    "            history = self.model.fit(\n",
    "                self,\n",
    "                epochs=self.params['epochs'],\n",
    "                validation_data=self.get_validation_data(),\n",
    "                callbacks=[cal1, cal2],\n",
    "                verbose=1\n",
    "            )\n",
    "            logger.info(\"Model training successfully completed\")\n",
    "            return history.history\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Training process failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def run_training_pipeline(self):\n",
    "        \"\"\"\n",
    "        Executes the complete training workflow from loading to training.\n",
    "        \"\"\"\n",
    "        logger.info(\"Launching full training workflow\")\n",
    "        try:\n",
    "            X, y = self.load_data()\n",
    "            X_train, X_test, y_train, y_test = self.split_data(X, y)\n",
    "            del X, y\n",
    "            gc.collect()\n",
    "            logger.info(\"Intermediate dataset cleared from memory\")\n",
    "\n",
    "            self.preprocess_data(X_train, X_test, y_train, y_test)\n",
    "            history = self.train()\n",
    "            logger.info(\"Training workflow executed successfully\")\n",
    "            return history\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Pipeline execution failed: {e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24345c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-09 13:19:55,571: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-08-09 13:19:55,581: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-08-09 13:19:55,585: INFO: common: created directory at: artifacts]\n",
      "[2025-08-09 13:19:55,585: INFO: common: created directory at: artifacts/model_trainer]\n",
      "[2025-08-09 13:19:55,585: INFO: 1075094852: ModelTrainer instance created]\n",
      "[2025-08-09 13:19:55,590: INFO: 1075094852: Launching full training workflow]\n",
      "[2025-08-09 13:19:55,590: INFO: 1075094852: Attempting to load dataset from artifacts\\data_preprocessing\\pickle]\n",
      "[2025-08-09 13:19:58,498: INFO: 1075094852: Dataset loaded successfully: X=(9501, 49152), y=(9501, 2)]\n",
      "[2025-08-09 13:19:58,501: INFO: 1075094852: Partitioning dataset into training and testing sets]\n",
      "[2025-08-09 13:19:59,570: INFO: 1075094852: Train: X=(7600, 49152), y=(7600, 2) | Test: X=(1901, 49152), y=(1901, 2)]\n",
      "[2025-08-09 13:19:59,938: INFO: 1075094852: Intermediate dataset cleared from memory]\n",
      "[2025-08-09 13:19:59,939: INFO: 1075094852: Starting preprocessing of dataset]\n",
      "[2025-08-09 13:19:59,941: INFO: 1075094852: Reshaped: X_train=(7600, 128, 128, 3), X_test=(1901, 128, 128, 3)]\n",
      "[2025-08-09 13:19:59,942: INFO: 1075094852: Reshaped: y_train=(7600, 2), y_test=(1901, 2)]\n",
      "[2025-08-09 13:19:59,944: INFO: 1075094852: Data preprocessing finished]\n",
      "[2025-08-09 13:19:59,945: INFO: 1075094852: Initiating training sequence]\n",
      "[2025-08-09 13:19:59,946: INFO: 1075094852: Constructing CNN model architecture]\n",
      "[2025-08-09 13:20:00,125: INFO: 1075094852: CNN model successfully built]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\forgery detection model\\.imagemodel\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m3,211,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,267,778</span> (12.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,267,778\u001b[0m (12.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,267,778</span> (12.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,267,778\u001b[0m (12.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 179ms/step - accuracy: 0.8364 - f1_score: 0.7519 - loss: 0.3227 - precision: 0.8364 - recall: 0.8364 - val_accuracy: 0.8681 - val_f1_score: 0.8188 - val_loss: 0.3397 - val_precision: 0.8681 - val_recall: 0.8681\n",
      "Epoch 2/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 176ms/step - accuracy: 0.8646 - f1_score: 0.8188 - loss: 0.2830 - precision: 0.8646 - recall: 0.8646 - val_accuracy: 0.8644 - val_f1_score: 0.8285 - val_loss: 0.2877 - val_precision: 0.8644 - val_recall: 0.8644\n",
      "Epoch 3/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 175ms/step - accuracy: 0.8689 - f1_score: 0.8238 - loss: 0.2768 - precision: 0.8689 - recall: 0.8689 - val_accuracy: 0.8745 - val_f1_score: 0.8346 - val_loss: 0.2689 - val_precision: 0.8745 - val_recall: 0.8745\n",
      "Epoch 4/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 174ms/step - accuracy: 0.8820 - f1_score: 0.8407 - loss: 0.2478 - precision: 0.8820 - recall: 0.8820 - val_accuracy: 0.8697 - val_f1_score: 0.7949 - val_loss: 0.2704 - val_precision: 0.8697 - val_recall: 0.8697\n",
      "Epoch 5/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 174ms/step - accuracy: 0.8993 - f1_score: 0.8619 - loss: 0.2095 - precision: 0.8993 - recall: 0.8993 - val_accuracy: 0.9052 - val_f1_score: 0.8728 - val_loss: 0.2113 - val_precision: 0.9052 - val_recall: 0.9052\n",
      "Epoch 6/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 176ms/step - accuracy: 0.9252 - f1_score: 0.8937 - loss: 0.1662 - precision: 0.9252 - recall: 0.9252 - val_accuracy: 0.9068 - val_f1_score: 0.8664 - val_loss: 0.1995 - val_precision: 0.9068 - val_recall: 0.9068\n",
      "Epoch 7/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 175ms/step - accuracy: 0.9387 - f1_score: 0.9119 - loss: 0.1358 - precision: 0.9387 - recall: 0.9387 - val_accuracy: 0.9084 - val_f1_score: 0.8508 - val_loss: 0.2143 - val_precision: 0.9084 - val_recall: 0.9084\n",
      "Epoch 8/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 175ms/step - accuracy: 0.9479 - f1_score: 0.9244 - loss: 0.1150 - precision: 0.9479 - recall: 0.9479 - val_accuracy: 0.9206 - val_f1_score: 0.8858 - val_loss: 0.1914 - val_precision: 0.9206 - val_recall: 0.9206\n",
      "Epoch 9/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 179ms/step - accuracy: 0.9589 - f1_score: 0.9404 - loss: 0.0993 - precision: 0.9589 - recall: 0.9589 - val_accuracy: 0.9163 - val_f1_score: 0.8771 - val_loss: 0.2134 - val_precision: 0.9163 - val_recall: 0.9163\n",
      "Epoch 10/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 173ms/step - accuracy: 0.9680 - f1_score: 0.9534 - loss: 0.0762 - precision: 0.9680 - recall: 0.9680 - val_accuracy: 0.9296 - val_f1_score: 0.8981 - val_loss: 0.2017 - val_precision: 0.9296 - val_recall: 0.9296\n",
      "Epoch 11/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 173ms/step - accuracy: 0.9706 - f1_score: 0.9572 - loss: 0.0705 - precision: 0.9706 - recall: 0.9706 - val_accuracy: 0.9216 - val_f1_score: 0.8893 - val_loss: 0.2234 - val_precision: 0.9216 - val_recall: 0.9216\n",
      "Epoch 12/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 173ms/step - accuracy: 0.9739 - f1_score: 0.9618 - loss: 0.0652 - precision: 0.9739 - recall: 0.9739 - val_accuracy: 0.9243 - val_f1_score: 0.8895 - val_loss: 0.2802 - val_precision: 0.9243 - val_recall: 0.9243\n",
      "Epoch 13/15\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 174ms/step - accuracy: 0.9790 - f1_score: 0.9694 - loss: 0.0542 - precision: 0.9790 - recall: 0.9790 - val_accuracy: 0.9025 - val_f1_score: 0.8408 - val_loss: 0.3795 - val_precision: 0.9025 - val_recall: 0.9025\n",
      "[2025-08-09 13:29:03,779: INFO: 1075094852: Model training successfully completed]\n",
      "[2025-08-09 13:29:03,781: INFO: 1075094852: Training workflow executed successfully]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    model_trainer_config = config_manager.get_model_trainer_config()\n",
    "    trainer = ModelTrainer(config=model_trainer_config)\n",
    "    history = trainer.run_training_pipeline()\n",
    "except Exception as e:\n",
    "        logger.error(f\"Pipeline failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca974142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".imagemodel (3.10.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
